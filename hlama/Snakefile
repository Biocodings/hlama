# -*- coding: utf-8 -*-
"""Standard generic HLA-MA Snakfile"""

from hlama import snake

schema = snake.build_schema('data.json')
schema_mode = schema.get_schema_type()

shell.executable('/bin/bash')
shell.prefix('set -e -o pipefail; ')

localrules: all

# TODO: yara multi-threading

rule all:
    input: 'report.txt'

onsuccess:
    schema.cleanup()

onerror:
    schema.cleanup()

rule make_report:
    output: 'report.txt'
    input: list(schema.get_report_input())
    run:
        schema.check_consistency(output[0], schema_mode)

# Extensions of YARA indices
YARA_EXTS = (
    '', '.lf.drp', '.lf.drs', '.lf.drv', '.lf.pst',
    '.rid.concat', '.rid.limits', '.sa.ind', '.sa.len',
    '.sa.val', '.txt.concat', '.txt.limits', '.txt.size')

rule yara_index_dna:
    params:
        cmd_prefix=schema.command_prefix(),
        hla_ref=schema.get_hla_dna_ref(),
    output:
        expand('tmp/ref_dna.fasta{ext}', ext=YARA_EXTS)
    shell:
        r"""
        {params.cmd_prefix}

        zcat {params.hla_ref} >{output[0]}

        yara_indexer \
            -o {output[0]} \
            {output[0]}
        """

rule yara_index_rna:
    params:
        cmd_prefix=schema.command_prefix(),
        hla_ref=schema.get_hla_rna_ref(),
    output:
        expand('tmp/ref_rna.fasta{ext}', ext=YARA_EXTS)
    shell:
        r"""
        {params.cmd_prefix}

        zcat {params.hla_ref} >{output[0]}

        yara_indexer \
            -o {output[0]} \
            {output[0]}
        """

def get_seq_specific_ref(wildcards):
    "Input function for rule call_hla"
    seq_type = schema.get_seq_type(wildcards)
    if seq_type == "RNA":
        return expand('tmp/ref_rna.fasta{ext}', ext=YARA_EXTS)
    else:
        return expand('tmp/ref_dna.fasta{ext}', ext=YARA_EXTS)

rule call_hla:
    params:
        cmd_prefix=schema.command_prefix(),
        optitype_ini=schema.optitype_ini_path,
        yara_threads=schema.yara_threads(),
    input:
        get_seq_specific_ref
    output:
        hla_types='{sample}.d/hla_types.txt'
    run:
        first_reads = ' '.join(schema.get_first_read_paths(wildcards))
        second_reads = ' '.join(schema.get_second_read_paths(wildcards))

        shell(r"""
        {params.cmd_prefix}

        # Setup temporary directory for prefiltered reads and Optitype
        # to work in.  Use trap for automatic cleanup.
        export TMPDIR=$(mktemp -d)
        trap "rm -rf $TMPDIR" EXIT KILL TERM INT HUP

        # Helper function for pre-filtering reads using Yara
        map()
        {{
            yara_mapper -t {params.yara_threads} -e 4 {input[0]} $1 \
            | samtools view -Sb -F 4 \
            | samtools bam2fq - \
            >> $2
        }}

        # Pre-filter left reads
        for reads in {first_reads}; do
            map $reads $TMPDIR/reads_1.fq
        done

        # Pre-filter right reads
        for reads in {second_reads}; do
            map $reads $TMPDIR/reads_2.fq
        done
        test -s $TMPDIR/reads_2.fq || rm -f $TMPDIR/reads_2.fq

        if [[ ! -s $TMPDIR/reads_1.fq ]]; then
            echo "FATAL ERROR: No reads mapped to HLA genes"
            echo "FATAL ERROR:"
            echo "FATAL ERROR: Are you sure your enrichment/capture kit contains"
            echo "FATAL ERROR: probes in the HLA regions?"
            exit 1
        fi

        # Perform calling with optitype
        OptiTypePipeline.py \
            --config {params.optitype_ini} \
            --input $TMPDIR/reads_?.fq \
            --dna \
            -o $TMPDIR/out.tmp

        # Move out results
        prefix=$(basename $(ls $TMPDIR/out.tmp | head -n 1))
        mv $TMPDIR/out.tmp/$prefix/${{prefix}}_coverage_plot.pdf \
            {wildcards.sample}.d/coverage_plot.pdf
        mv $TMPDIR/out.tmp/$prefix/${{prefix}}_result.tsv \
            {wildcards.sample}.d/result.tsv
        tail -n +2 {wildcards.sample}.d/result.tsv \
        | cut -f 2-7 \
        | tr '\t' '\n' \
        | sort -V \
        > {wildcards.sample}.d/hla_types.txt
        """)
